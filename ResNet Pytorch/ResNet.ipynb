{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPt48HDF0v0L0g7zKeY2kAw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ResNet-50 architecture\n","\n","<img src=\"https://cdn-5f733ed3c1ac190fbc56ef88.closte.com/wp-content/uploads/2019/07/ResNet50_architecture-1.png\"  width=\"500\" height=\"3000\">"],"metadata":{"id":"oQIT8jOyk7NK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jDMZPMAirhCM"},"outputs":[],"source":["\"\"\"\n","From scratch implementation of the famous ResNet models.\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","\n","class block(nn.Module):\n","  def __init__(\n","      self, in_channels,  intermediate_channels, identity_downsample=None, stride=1\n","      ):\n","    super().__init__()\n","    self.expansion = 4\n","    self.conv1 = nn.Conv2d(\n","                            in_channels,\n","                            intermediate_channels,\n","                            kernel_size=1,\n","                            stride=1,\n","                            padding=0,\n","                            bias=False \n","                            )                 # for example if \n","    self.bn1 = nn.BatchNorm2d(intermediate_channels)\n","\n","    self.conv2 = nn.Conv2d(\n","                            intermediate_channels,\n","                            intermediate_channels,\n","                            kernel_size=3,\n","                            stride=stride,\n","                            padding=1,\n","                            bias=False \n","                            )\n","    self.bn2 = nn.BatchNorm2d(intermediate_channels)\n","\n","    self.conv3 = nn.Conv2d(\n","                            intermediate_channels,\n","                            intermediate_channels * self.expansion,\n","                            kernel_size=1,\n","                            stride=1,\n","                            padding=0,\n","                            bias=False \n","                            )\n","    self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n","\n","    self.relu = nn.ReLU()\n","    self.identity_downsample = identity_downsample\n","    self.stride = stride\n","\n","  def forward(self, x):\n","    identity = x.clone()  # deep copy\n","\n","    x = self.conv1(x)\n","    x = self.bn1(x)\n","    x = self.relu(x)\n","    x = self.conv2(x)\n","    x = self.bn2(x)\n","    x = self.relu(x)\n","    x = self.conv3(x)\n","    x = self.bn3(x)\n","\n","    if self.identity_downsample is not None:\n","      identity = self.identity_downsample(identity)\n","\n","    x += identity\n","    x = self.relu(x)\n","    return x\n","\n","\n","\n","\n","\n","class ResNet(nn.Module):\n","  def __init__(self, block, num_block, image_channels, num_classes):   # lyers ->for example [3, 4, 6, 3]\n","    super(ResNet, self).__init__()\n","    self.in_channels = 64\n","\n","    self.conv1 = nn.Conv2d(\n","        image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False\n","    )\n","    self.bn1 = nn.BatchNorm2d(64)\n","    self.relu = nn.ReLU()\n","    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","    # Essentially the entire ResNet architecture are in these 4 lines below\n","    self.layer1 = self._make_layer(\n","                            block, num_block[0], intermediate_channels=64, stride=1)\n","    self.layer2 = self._make_layer(\n","                            block, num_block[1], intermediate_channels=128, stride=2)\n","    self.layer3 = self._make_layer(\n","                            block, num_block[2], intermediate_channels=256, stride=2)\n","    self.layer4 = self._make_layer(\n","                            block, num_block[3], intermediate_channels=512, stride=2)\n","    \n","    # In AdaptiveAvgPool2d you specify output size. in below example we get a 1*1 size for each channel\n","    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","    self.fc = nn.Linear(512 * 4, num_classes)\n","\n","\n","  def forward(self, x):\n","      x = self.conv1(x)\n","      x = self.bn1(x)\n","      x = self.relu(x)\n","      x = self.maxpool(x)\n","      x = self.layer1(x)\n","      x = self.layer2(x)\n","      x = self.layer3(x)\n","      x = self.layer4(x)\n","\n","      x = self.avgpool(x)\n","      x = x.reshape(x.shape[0], -1)\n","      x = self.fc(x)\n","\n","      return x\n","\n","\n","  def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n","      identity_downsample = None\n","      layers = []\n","\n","\n","      # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n","      # we need to adapt the Identity (skip connection) so it will be able to be added\n","      # to the layer that's ahead\n","      if stride != 1 or self.in_channels != intermediate_channels * 4:\n","          identity_downsample = nn.Sequential(\n","              nn.Conv2d(\n","                  self.in_channels,\n","                  intermediate_channels * 4,\n","                  kernel_size=1,\n","                  stride=stride,\n","                  bias=False,\n","              ),\n","              nn.BatchNorm2d(intermediate_channels * 4)\n","          )\n","\n","      # The first operation of each layer (layer here means a collection of blocks) is reducing the dimension,\n","      # so we also need to resize the volume that goes through the skip connection\n","      # so in below line we downsample for the first block\n","      layers.append(\n","          block(self.in_channels, intermediate_channels, identity_downsample, stride)\n","      )\n","      \n","      # input channel of second block of each layer should be changed as below\n","      # The expansion size is always 4 for ResNet 50,101,152\n","      self.in_channels = intermediate_channels * 4\n","\n","      # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n","      # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n","      # and also same amount of channels.\n","      for i in range(num_residual_blocks - 1):\n","          layers.append(block(self.in_channels, intermediate_channels))\n","\n","      return nn.Sequential(*layers)\n","\n","\n","def ResNet50(img_channel=3, num_classes=1000):\n","    return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)\n","\n","\n","\n","def ResNet101(img_channel=3, num_classes=1000):\n","    return ResNet(block, [3, 4, 23, 3], img_channel, num_classes)\n","\n","\n","def ResNet152(img_channel=3, num_classes=1000):\n","    return ResNet(block, [3, 8, 36, 3], img_channel, num_classes)     \n"]},{"cell_type":"markdown","source":["# finding output size of convolutional layer\n","\n","<img src=\"https://miro.medium.com/v2/resize:fit:358/format:webp/1*SaaR10uSdDFBP3EVNrZwnA.png\"  width=\"300\" height=\"100\">\n","\n","The result of the quotient of above equation is always rounded off. This is represented mathematically by the floor function. \n","\n","**Hint**: These ‘floor-parenthesis’ can easily be perceived incorrectly as square brackets. Do not make this mistake!\n","\n","— *If the kernel does not ‘fit’ into the input array* —\n","\n","By rounding off the result, the ‘dropping’ of superfluous rows and columns on the border is described mathematically. That means, if the kernel with a specific stride does not fit into the input array, a float value is generated as a result. Because the remaining pixels of the input array do not impact the output array, the result is rounded off.\n","\n","\n","<img src=\"https://miro.medium.com/v2/resize:fit:828/format:webp/1*9rOrbW8-MHMzt2yM9A1lEQ.png\"  width=\"500\" height=\"250\">\n","\n","<img src=\"https://miro.medium.com/v2/resize:fit:828/format:webp/1*bH3vy608kUUn3wBvEXUBJw.png\"  width=\"500\" height=\"250\">\n","\n","<img src=\"https://miro.medium.com/v2/resize:fit:828/format:webp/1*0Fu9UbpTmbIkfPLV-34cuw.png\"  width=\"500\" height=\"250\">\n","\n","<img src=\"https://miro.medium.com/v2/resize:fit:828/format:webp/1*PbXsNYcVpk9vCG45Z0lHdQ.png\"  width=\"500\" height=\"250\">\n","\n","\n","\n","For the example of above :\n","\n","<img src=\"https://miro.medium.com/v2/resize:fit:608/format:webp/1*lbGuvjqQrJYdVkFPAzwK3A.png\"  width=\"400\" height=\"100\">\n","\n","The behavior of dropping the remaining pixels can be omitted by the application of padding. If padding of one pixel on the top, the bottom, the left, and the right border is applied, the kernel covers all values of the input array\n","\n","<img src=\"https://miro.medium.com/v2/resize:fit:786/format:webp/1*UKLpbHzeDDuDBcO7oYjt4g.png\"  width=\"600\" height=\"300\">\n","\n","But there is still one row and one column of pixels dropped in this process. just zero-padded values are dropped out, which leads to no information loss.\n","\n","for more information on this topic got to https://towardsdatascience.com/a-comprehensible-explanation-of-the-dimensions-in-cnns-841dba49df5e"],"metadata":{"id":"O7Ryy-Wem_09"}},{"cell_type":"markdown","source":["**Output size calculation after applying convolution**\n","\n","\n","0. Input Layer shape = 3 * 224 * 224  -> (color channels, height, width)\n","\n","1. After applying conv2d with 64 filters of (7*7) stride = 2 and padding = 3:\n","\n","* Output shape = ((224 + 2*3 - 7) / 2) + 1 = 112.5   ---after floor round---> 112\n","\n","2. After applying Max Pooling (3*3) stride = 2 and padding = 1:\n","\n","* Output shape = ((112 + 2*1 - 3) / 2) + 1 = 56\n","\n","___\n","\n","3. After applying conv2d with 64 filters of (1*1) stride = 1 and padding = 0:\n","\n","* Output shape = ((56 + 2*0 - 1) / 1) + 1 = 56\n","\n","4. After applying conv2d with 64 filters of (3*3) stride = 1 and padding = 1:\n","\n","* Output shape = ((56 + 2*1 - 3) / 1) + 1 = 56\n","\n","5. After applying conv2d with 256 (64 * 4) filters of (1*1) stride = 1 and padding = 0:\n","\n","* Output shape = ((56 + 2*0 - 1) / 1) + 1 = 56\n","\n","\n","---\n","\n","6. After applying conv2d with 128 filters of (1*1) stride = 2 and padding = 0:\n","\n","* Output shape = ((58 + 2*0 - 1) / 2) + 1 = 28\n","\n","7. After applying conv2d with 128 filters of (3*3) stride = 2 and padding = 1:\n","\n","* Output shape = ((56 + 2*1 - 3) / 2) + 1 = 28\n","\n","8. After applying conv2d with 512 (128 * 4) filters of (1*1) stride = 2 and padding = 0:\n","\n","* Output shape = ((56 + 2*0 - 1) / 2) + 1 = 28\n","\n","___\n","\n","9. After applying conv2d with 256 filters of (1*1) stride = 2 and padding = 0:\n","\n","* Output shape = ((28 + 2*0 - 1) / 2) + 1 = 14\n","\n","10. After applying conv2d with 256 filters of (3*3) stride = 2 and padding = 1:\n","\n","* Output shape = ((28 + 2*1 - 3) / 2) + 1 = 14\n","\n","11. After applying conv2d with 1024 (256 * 4) filters of (1*1) stride = 2 and padding = 0:\n","\n","* Output shape = ((28 + 2*0 - 1) / 2) + 1 = 14\n","\n","---\n","\n","\n","12. After applying conv2d with 512 filters of (1*1) stride = 2 and padding = 0:\n","\n","* Output shape = ((14 + 2*0 - 1) / 2) + 1 = 7\n","\n","13. After applying conv2d with 512 filters of (3*3) stride = 2 and padding = 1:\n","\n","* Output shape = ((14 + 2*1 - 3) / 2) + 1 = 7\n","\n","14. After applying conv2d with 2048 (512 * 4) filters of (1*1) stride = 2 and padding = 0:\n","\n","* Output shape = ((14 + 2*0 - 1) / 2) + 1 = 7\n","\n","\n"],"metadata":{"id":"ckoJVZe_OyYl"}},{"cell_type":"markdown","source":["# Identity Shortcut and Projection Shortcut\n","\n","This difference on the skip connections are the so called in the paper as Identity Shortcut and Projection Shortcut. The identity shortcut is the one we have already discussed, simply bypassing the input volume to the addition operator. The projection shortcut performs a convolution operation to ensure the volumes at this addition operation are the same size. From the paper we can see that there are 2 options for matching the output size. Either padding the input volume or perform 1x1 convolutions. Here, this second option is shown.\n","\n"],"metadata":{"id":"BrLiyvsjhBGm"}},{"cell_type":"markdown","source":["# understanding and visualizing ResNet\n","\n","go to below urls to learn more about ResNet visually\n","\n","https://towardsdatascience.com/understanding-and-visualizing-resnets-442284831be8\n","\n","https://cv-tricks.com/keras/understand-implement-resnets/"],"metadata":{"id":"cFXaR-u7h1O5"}},{"cell_type":"code","source":["try:\n","  from torchinfo import summary\n","except:\n","  ! pip install torchinfo\n","  from torchinfo import summary"],"metadata":{"id":"kX8eA0s3egZ9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679411946692,"user_tz":-210,"elapsed":5988,"user":{"displayName":"yasin","userId":"00554470259111997069"}},"outputId":"810bce89-00eb-40a8-886a-0f214fe51a6c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchinfo\n","  Downloading torchinfo-1.7.2-py3-none-any.whl (22 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.7.2\n"]}]},{"cell_type":"markdown","source":["# ResNet-50"],"metadata":{"id":"TPB8UkiVxWVj"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","net = ResNet50(img_channel=3, num_classes=1000).to(device)\n","\n","summary(\n","    net,\n","    (32,3,223,223),\n","    col_width=25,\n","    col_names=[\"kernel_size\",\"input_size\", \"output_size\", \"num_params\"],\n","    row_settings=[\"var_names\"],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1dKCfrMMes_w","executionInfo":{"status":"ok","timestamp":1679411957356,"user_tz":-210,"elapsed":10187,"user":{"displayName":"yasin","userId":"00554470259111997069"}},"outputId":"2b36a232-554d-4e72-97ea-1bbd08fe6070"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["======================================================================================================================================================\n","Layer (type (var_name))                            Kernel Shape              Input Shape               Output Shape              Param #\n","======================================================================================================================================================\n","ResNet (ResNet)                                    --                        [32, 3, 223, 223]         [32, 1000]                --\n","├─Conv2d (conv1)                                   [7, 7]                    [32, 3, 223, 223]         [32, 64, 112, 112]        9,408\n","├─BatchNorm2d (bn1)                                --                        [32, 64, 112, 112]        [32, 64, 112, 112]        128\n","├─ReLU (relu)                                      --                        [32, 64, 112, 112]        [32, 64, 112, 112]        --\n","├─MaxPool2d (maxpool)                              3                         [32, 64, 112, 112]        [32, 64, 56, 56]          --\n","├─Sequential (layer1)                              --                        [32, 64, 56, 56]          [32, 256, 56, 56]         --\n","│    └─block (0)                                   --                        [32, 64, 56, 56]          [32, 256, 56, 56]         --\n","│    │    └─Conv2d (conv1)                         [1, 1]                    [32, 64, 56, 56]          [32, 64, 56, 56]          4,096\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 64, 56, 56]          [32, 64, 56, 56]          128\n","│    │    └─ReLU (relu)                            --                        [32, 64, 56, 56]          [32, 64, 56, 56]          --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 64, 56, 56]          [32, 64, 56, 56]          36,864\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 64, 56, 56]          [32, 64, 56, 56]          128\n","│    │    └─ReLU (relu)                            --                        [32, 64, 56, 56]          [32, 64, 56, 56]          --\n","│    │    └─Conv2d (conv3)                         [1, 1]                    [32, 64, 56, 56]          [32, 256, 56, 56]         16,384\n","│    │    └─BatchNorm2d (bn3)                      --                        [32, 256, 56, 56]         [32, 256, 56, 56]         512\n","│    │    └─Sequential (identity_downsample)       --                        [32, 64, 56, 56]          [32, 256, 56, 56]         16,896\n","│    │    └─ReLU (relu)                            --                        [32, 256, 56, 56]         [32, 256, 56, 56]         --\n","│    └─block (1)                                   --                        [32, 256, 56, 56]         [32, 256, 56, 56]         --\n","│    │    └─Conv2d (conv1)                         [1, 1]                    [32, 256, 56, 56]         [32, 64, 56, 56]          16,384\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 64, 56, 56]          [32, 64, 56, 56]          128\n","│    │    └─ReLU (relu)                            --                        [32, 64, 56, 56]          [32, 64, 56, 56]          --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 64, 56, 56]          [32, 64, 56, 56]          36,864\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 64, 56, 56]          [32, 64, 56, 56]          128\n","│    │    └─ReLU (relu)                            --                        [32, 64, 56, 56]          [32, 64, 56, 56]          --\n","│    │    └─Conv2d (conv3)                         [1, 1]                    [32, 64, 56, 56]          [32, 256, 56, 56]         16,384\n","│    │    └─BatchNorm2d (bn3)                      --                        [32, 256, 56, 56]         [32, 256, 56, 56]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 56, 56]         [32, 256, 56, 56]         --\n","│    └─block (2)                                   --                        [32, 256, 56, 56]         [32, 256, 56, 56]         --\n","│    │    └─Conv2d (conv1)                         [1, 1]                    [32, 256, 56, 56]         [32, 64, 56, 56]          16,384\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 64, 56, 56]          [32, 64, 56, 56]          128\n","│    │    └─ReLU (relu)                            --                        [32, 64, 56, 56]          [32, 64, 56, 56]          --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 64, 56, 56]          [32, 64, 56, 56]          36,864\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 64, 56, 56]          [32, 64, 56, 56]          128\n","│    │    └─ReLU (relu)                            --                        [32, 64, 56, 56]          [32, 64, 56, 56]          --\n","│    │    └─Conv2d (conv3)                         [1, 1]                    [32, 64, 56, 56]          [32, 256, 56, 56]         16,384\n","│    │    └─BatchNorm2d (bn3)                      --                        [32, 256, 56, 56]         [32, 256, 56, 56]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 56, 56]         [32, 256, 56, 56]         --\n","├─Sequential (layer2)                              --                        [32, 256, 56, 56]         [32, 512, 28, 28]         --\n","│    └─block (0)                                   --                        [32, 256, 56, 56]         [32, 512, 28, 28]         --\n","│    │    └─Conv2d (conv1)                         [1, 1]                    [32, 256, 56, 56]         [32, 128, 56, 56]         32,768\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 128, 56, 56]         [32, 128, 56, 56]         256\n","│    │    └─ReLU (relu)                            --                        [32, 128, 56, 56]         [32, 128, 56, 56]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 128, 56, 56]         [32, 128, 28, 28]         147,456\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 128, 28, 28]         [32, 128, 28, 28]         256\n","│    │    └─ReLU (relu)                            --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","│    │    └─Conv2d (conv3)                         [1, 1]                    [32, 128, 28, 28]         [32, 512, 28, 28]         65,536\n","│    │    └─BatchNorm2d (bn3)                      --                        [32, 512, 28, 28]         [32, 512, 28, 28]         1,024\n","│    │    └─Sequential (identity_downsample)       --                        [32, 256, 56, 56]         [32, 512, 28, 28]         132,096\n","│    │    └─ReLU (relu)                            --                        [32, 512, 28, 28]         [32, 512, 28, 28]         --\n","│    └─block (1)                                   --                        [32, 512, 28, 28]         [32, 512, 28, 28]         --\n","│    │    └─Conv2d (conv1)                         [1, 1]                    [32, 512, 28, 28]         [32, 128, 28, 28]         65,536\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 128, 28, 28]         [32, 128, 28, 28]         256\n","│    │    └─ReLU (relu)                            --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 128, 28, 28]         [32, 128, 28, 28]         147,456\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 128, 28, 28]         [32, 128, 28, 28]         256\n","│    │    └─ReLU (relu)                            --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","│    │    └─Conv2d (conv3)                         [1, 1]                    [32, 128, 28, 28]         [32, 512, 28, 28]         65,536\n","│    │    └─BatchNorm2d (bn3)                      --                        [32, 512, 28, 28]         [32, 512, 28, 28]         1,024\n","│    │    └─ReLU (relu)                            --                        [32, 512, 28, 28]         [32, 512, 28, 28]         --\n","│    └─block (2)                                   --                        [32, 512, 28, 28]         [32, 512, 28, 28]         --\n","│    │    └─Conv2d (conv1)                         [1, 1]                    [32, 512, 28, 28]         [32, 128, 28, 28]         65,536\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 128, 28, 28]         [32, 128, 28, 28]         256\n","│    │    └─ReLU (relu)                            --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 128, 28, 28]         [32, 128, 28, 28]         147,456\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 128, 28, 28]         [32, 128, 28, 28]         256\n","│    │    └─ReLU (relu)                            --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","│    │    └─Conv2d (conv3)                         [1, 1]                    [32, 128, 28, 28]         [32, 512, 28, 28]         65,536\n","│    │    └─BatchNorm2d (bn3)                      --                        [32, 512, 28, 28]         [32, 512, 28, 28]         1,024\n","│    │    └─ReLU (relu)                            --                        [32, 512, 28, 28]         [32, 512, 28, 28]         --\n","│    └─block (3)                                   --                        [32, 512, 28, 28]         [32, 512, 28, 28]         --\n","│    │    └─Conv2d (conv1)                         [1, 1]                    [32, 512, 28, 28]         [32, 128, 28, 28]         65,536\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 128, 28, 28]         [32, 128, 28, 28]         256\n","│    │    └─ReLU (relu)                            --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 128, 28, 28]         [32, 128, 28, 28]         147,456\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 128, 28, 28]         [32, 128, 28, 28]         256\n","│    │    └─ReLU (relu)                            --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","│    │    └─Conv2d (conv3)                         [1, 1]                    [32, 128, 28, 28]         [32, 512, 28, 28]         65,536\n","│    │    └─BatchNorm2d (bn3)                      --                        [32, 512, 28, 28]         [32, 512, 28, 28]         1,024\n","│    │    └─ReLU (relu)                            --                        [32, 512, 28, 28]         [32, 512, 28, 28]         --\n","├─Sequential (layer3)                              --                        [32, 512, 28, 28]         [32, 1024, 14, 14]        --\n","│    └─block (0)                                   --                        [32, 512, 28, 28]         [32, 1024, 14, 14]        --\n","│    │    └─Conv2d (conv1)                         [1, 1]                    [32, 512, 28, 28]         [32, 256, 28, 28]         131,072\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 256, 28, 28]         [32, 256, 28, 28]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 28, 28]         [32, 256, 28, 28]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 256, 28, 28]         [32, 256, 14, 14]         589,824\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv3)                         [1, 1]                    [32, 256, 14, 14]         [32, 1024, 14, 14]        262,144\n","│    │    └─BatchNorm2d (bn3)                      --                        [32, 1024, 14, 14]        [32, 1024, 14, 14]        2,048\n","│    │    └─Sequential (identity_downsample)       --                        [32, 512, 28, 28]         [32, 1024, 14, 14]        526,336\n","│    │    └─ReLU (relu)                            --                        [32, 1024, 14, 14]        [32, 1024, 14, 14]        --\n","│    └─block (1)                                   --                        [32, 1024, 14, 14]        [32, 1024, 14, 14]        --\n","│    │    └─Conv2d (conv1)                         [1, 1]                    [32, 1024, 14, 14]        [32, 256, 14, 14]         262,144\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 256, 14, 14]         [32, 256, 14, 14]         589,824\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv3)                         [1, 1]                    [32, 256, 14, 14]         [32, 1024, 14, 14]        262,144\n","│    │    └─BatchNorm2d (bn3)                      --                        [32, 1024, 14, 14]        [32, 1024, 14, 14]        2,048\n","│    │    └─ReLU (relu)                            --                        [32, 1024, 14, 14]        [32, 1024, 14, 14]        --\n","│    └─block (2)                                   --                        [32, 1024, 14, 14]        [32, 1024, 14, 14]        --\n","│    │    └─Conv2d (conv1)                         [1, 1]                    [32, 1024, 14, 14]        [32, 256, 14, 14]         262,144\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 256, 14, 14]         [32, 256, 14, 14]         589,824\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv3)                         [1, 1]                    [32, 256, 14, 14]         [32, 1024, 14, 14]        262,144\n","│    │    └─BatchNorm2d (bn3)                      --                        [32, 1024, 14, 14]        [32, 1024, 14, 14]        2,048\n","│    │    └─ReLU (relu)                            --                        [32, 1024, 14, 14]        [32, 1024, 14, 14]        --\n","│    └─block (3)                                   --                        [32, 1024, 14, 14]        [32, 1024, 14, 14]        --\n","│    │    └─Conv2d (conv1)                         [1, 1]                    [32, 1024, 14, 14]        [32, 256, 14, 14]         262,144\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 256, 14, 14]         [32, 256, 14, 14]         589,824\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv3)                         [1, 1]                    [32, 256, 14, 14]         [32, 1024, 14, 14]        262,144\n","│    │    └─BatchNorm2d (bn3)                      --                        [32, 1024, 14, 14]        [32, 1024, 14, 14]        2,048\n","│    │    └─ReLU (relu)                            --                        [32, 1024, 14, 14]        [32, 1024, 14, 14]        --\n","│    └─block (4)                                   --                        [32, 1024, 14, 14]        [32, 1024, 14, 14]        --\n","│    │    └─Conv2d (conv1)                         [1, 1]                    [32, 1024, 14, 14]        [32, 256, 14, 14]         262,144\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 256, 14, 14]         [32, 256, 14, 14]         589,824\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv3)                         [1, 1]                    [32, 256, 14, 14]         [32, 1024, 14, 14]        262,144\n","│    │    └─BatchNorm2d (bn3)                      --                        [32, 1024, 14, 14]        [32, 1024, 14, 14]        2,048\n","│    │    └─ReLU (relu)                            --                        [32, 1024, 14, 14]        [32, 1024, 14, 14]        --\n","│    └─block (5)                                   --                        [32, 1024, 14, 14]        [32, 1024, 14, 14]        --\n","│    │    └─Conv2d (conv1)                         [1, 1]                    [32, 1024, 14, 14]        [32, 256, 14, 14]         262,144\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 256, 14, 14]         [32, 256, 14, 14]         589,824\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv3)                         [1, 1]                    [32, 256, 14, 14]         [32, 1024, 14, 14]        262,144\n","│    │    └─BatchNorm2d (bn3)                      --                        [32, 1024, 14, 14]        [32, 1024, 14, 14]        2,048\n","│    │    └─ReLU (relu)                            --                        [32, 1024, 14, 14]        [32, 1024, 14, 14]        --\n","├─Sequential (layer4)                              --                        [32, 1024, 14, 14]        [32, 2048, 7, 7]          --\n","│    └─block (0)                                   --                        [32, 1024, 14, 14]        [32, 2048, 7, 7]          --\n","│    │    └─Conv2d (conv1)                         [1, 1]                    [32, 1024, 14, 14]        [32, 512, 14, 14]         524,288\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 512, 14, 14]         [32, 512, 14, 14]         1,024\n","│    │    └─ReLU (relu)                            --                        [32, 512, 14, 14]         [32, 512, 14, 14]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 512, 14, 14]         [32, 512, 7, 7]           2,359,296\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 512, 7, 7]           [32, 512, 7, 7]           1,024\n","│    │    └─ReLU (relu)                            --                        [32, 512, 7, 7]           [32, 512, 7, 7]           --\n","│    │    └─Conv2d (conv3)                         [1, 1]                    [32, 512, 7, 7]           [32, 2048, 7, 7]          1,048,576\n","│    │    └─BatchNorm2d (bn3)                      --                        [32, 2048, 7, 7]          [32, 2048, 7, 7]          4,096\n","│    │    └─Sequential (identity_downsample)       --                        [32, 1024, 14, 14]        [32, 2048, 7, 7]          2,101,248\n","│    │    └─ReLU (relu)                            --                        [32, 2048, 7, 7]          [32, 2048, 7, 7]          --\n","│    └─block (1)                                   --                        [32, 2048, 7, 7]          [32, 2048, 7, 7]          --\n","│    │    └─Conv2d (conv1)                         [1, 1]                    [32, 2048, 7, 7]          [32, 512, 7, 7]           1,048,576\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 512, 7, 7]           [32, 512, 7, 7]           1,024\n","│    │    └─ReLU (relu)                            --                        [32, 512, 7, 7]           [32, 512, 7, 7]           --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 512, 7, 7]           [32, 512, 7, 7]           2,359,296\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 512, 7, 7]           [32, 512, 7, 7]           1,024\n","│    │    └─ReLU (relu)                            --                        [32, 512, 7, 7]           [32, 512, 7, 7]           --\n","│    │    └─Conv2d (conv3)                         [1, 1]                    [32, 512, 7, 7]           [32, 2048, 7, 7]          1,048,576\n","│    │    └─BatchNorm2d (bn3)                      --                        [32, 2048, 7, 7]          [32, 2048, 7, 7]          4,096\n","│    │    └─ReLU (relu)                            --                        [32, 2048, 7, 7]          [32, 2048, 7, 7]          --\n","│    └─block (2)                                   --                        [32, 2048, 7, 7]          [32, 2048, 7, 7]          --\n","│    │    └─Conv2d (conv1)                         [1, 1]                    [32, 2048, 7, 7]          [32, 512, 7, 7]           1,048,576\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 512, 7, 7]           [32, 512, 7, 7]           1,024\n","│    │    └─ReLU (relu)                            --                        [32, 512, 7, 7]           [32, 512, 7, 7]           --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 512, 7, 7]           [32, 512, 7, 7]           2,359,296\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 512, 7, 7]           [32, 512, 7, 7]           1,024\n","│    │    └─ReLU (relu)                            --                        [32, 512, 7, 7]           [32, 512, 7, 7]           --\n","│    │    └─Conv2d (conv3)                         [1, 1]                    [32, 512, 7, 7]           [32, 2048, 7, 7]          1,048,576\n","│    │    └─BatchNorm2d (bn3)                      --                        [32, 2048, 7, 7]          [32, 2048, 7, 7]          4,096\n","│    │    └─ReLU (relu)                            --                        [32, 2048, 7, 7]          [32, 2048, 7, 7]          --\n","├─AdaptiveAvgPool2d (avgpool)                      --                        [32, 2048, 7, 7]          [32, 2048, 1, 1]          --\n","├─Linear (fc)                                      --                        [32, 2048]                [32, 1000]                2,049,000\n","======================================================================================================================================================\n","Total params: 25,557,032\n","Trainable params: 25,557,032\n","Non-trainable params: 0\n","Total mult-adds (G): 130.86\n","======================================================================================================================================================\n","Input size (MB): 19.10\n","Forward/backward pass size (MB): 5690.62\n","Params size (MB): 102.23\n","Estimated Total Size (MB): 5811.94\n","======================================================================================================================================================"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["# ResNet-34"],"metadata":{"id":"n3inc66JxJ1-"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class block(nn.Module):\n","  def __init__(self, in_channels, block_channels, identity_downsample=None, stride=1):\n","    super().__init__()\n","    self.conv1 = nn.Conv2d(in_channels,block_channels,kernel_size=3,\n","                           stride=stride, padding=1)\n","    self.bn1 = nn.BatchNorm2d(block_channels)\n"," \n","\n","    self.conv2 = nn.Conv2d(block_channels, block_channels, kernel_size=3,\n","                           stride=1, padding=1)\n","    self.bn2 = nn.BatchNorm2d(block_channels)\n","    self.relu = nn.ReLU()\n","    self.identity_downsample = identity_downsample\n","\n","\n","  def forward(self,x):\n","    identity = x.clone()\n","\n","    x = self.conv1(x)\n","    x = self.bn1(x)\n","    x = self.relu(x)\n","    x = self.conv2(x)\n","    x = self.bn2(x)\n","\n","    if self.identity_downsample is not None:\n","      identity = self.identity_downsample(identity)\n","    \n","    x += identity\n","    x = self.relu(x)\n","\n","    return x\n","\n","\n","\n","\n","class ResNet34(nn.Module):\n","  def __init__(self, block, num_block, image_channels, num_classes):\n","    super().__init__()\n","\n","    self.in_channels = 64\n","    self.conv1 = nn.Conv2d(in_channels=image_channels, out_channels=64, kernel_size=7,\n","                           stride=2, padding=3)\n","    self.bn1 = nn.BatchNorm2d(64)\n","    self.relu = nn.ReLU()\n","    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","    self.layer1 = self._make_layer(block, num_block[0], block_channels=64, stride=1)\n","    self.layer2 = self._make_layer(block, num_block[1], block_channels=128, stride=2)\n","    self.layer3 = self._make_layer(block, num_block[2], block_channels=256, stride=2)\n","    self.layer4 = self._make_layer(block, num_block[3], block_channels=512, stride=2)\n","\n","    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","    self.fc = nn.Linear(512, num_classes)\n","\n","\n","\n","\n","  def forward(self,x):\n","    x = self.conv1(x)\n","    x = self.bn1(x)\n","    x = self.relu(x)\n","    x = self.maxpool(x)\n","    x = self.layer1(x)\n","    x = self.layer2(x)\n","    x = self.layer3(x)\n","    x = self.layer4(x)\n","    x = self.avgpool(x)\n","    x = x.view(x.shape[0], -1)\n","    x = self.fc(x)\n","\n","    return x\n","\n","\n","\n","  def _make_layer(self,block,num_residual_block, block_channels, stride):\n","    layers = []\n","    identity_downsample = None\n","\n","    if stride != 1 or self.in_channels != 2*block_channels:\n","      identity_downsample = nn.Sequential(\n","                                nn.Conv2d(self.in_channels, block_channels, kernel_size=1,\n","                                          stride=stride),\n","                                nn.BatchNorm2d(block_channels))\n","    \n","    layers.append(block(self.in_channels, block_channels, identity_downsample, stride))\n","    self.in_channels = block_channels\n","\n","    for layer in range(num_residual_block-1):\n","      layers.append(block(self.in_channels, block_channels))\n","\n","    return nn.Sequential(*layers)\n","\n","def ResNet(img_channel=3, num_classes=1000):\n","    return ResNet34(block, [3, 4, 6, 3], img_channel, num_classes)  "],"metadata":{"id":"-NQFRvwPfXMd","executionInfo":{"status":"ok","timestamp":1679563146745,"user_tz":-210,"elapsed":1254,"user":{"displayName":"yasin","userId":"00554470259111997069"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","net = ResNet(img_channel=3, num_classes=1000).to(device)\n","\n","summary(\n","    net,\n","    (32,3,224,224),\n","    col_width=25,\n","    col_names=[\"kernel_size\",\"input_size\", \"output_size\", \"num_params\"],\n","    row_settings=[\"var_names\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9s43ElTOfxHF","executionInfo":{"status":"ok","timestamp":1679563151162,"user_tz":-210,"elapsed":4422,"user":{"displayName":"yasin","userId":"00554470259111997069"}},"outputId":"90c140c0-508e-4db9-cce3-892868092081"},"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["======================================================================================================================================================\n","Layer (type (var_name))                            Kernel Shape              Input Shape               Output Shape              Param #\n","======================================================================================================================================================\n","ResNet34 (ResNet34)                                --                        [32, 3, 224, 224]         [32, 1000]                --\n","├─Conv2d (conv1)                                   [7, 7]                    [32, 3, 224, 224]         [32, 64, 112, 112]        9,472\n","├─BatchNorm2d (bn1)                                --                        [32, 64, 112, 112]        [32, 64, 112, 112]        128\n","├─ReLU (relu)                                      --                        [32, 64, 112, 112]        [32, 64, 112, 112]        --\n","├─MaxPool2d (maxpool)                              3                         [32, 64, 112, 112]        [32, 64, 56, 56]          --\n","├─Sequential (layer1)                              --                        [32, 64, 56, 56]          [32, 64, 56, 56]          --\n","│    └─block (0)                                   --                        [32, 64, 56, 56]          [32, 64, 56, 56]          --\n","│    │    └─Conv2d (conv1)                         [3, 3]                    [32, 64, 56, 56]          [32, 64, 56, 56]          36,928\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 64, 56, 56]          [32, 64, 56, 56]          128\n","│    │    └─ReLU (relu)                            --                        [32, 64, 56, 56]          [32, 64, 56, 56]          --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 64, 56, 56]          [32, 64, 56, 56]          36,928\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 64, 56, 56]          [32, 64, 56, 56]          128\n","│    │    └─Sequential (identity_downsample)       --                        [32, 64, 56, 56]          [32, 64, 56, 56]          4,288\n","│    │    └─ReLU (relu)                            --                        [32, 64, 56, 56]          [32, 64, 56, 56]          --\n","│    └─block (1)                                   --                        [32, 64, 56, 56]          [32, 64, 56, 56]          --\n","│    │    └─Conv2d (conv1)                         [3, 3]                    [32, 64, 56, 56]          [32, 64, 56, 56]          36,928\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 64, 56, 56]          [32, 64, 56, 56]          128\n","│    │    └─ReLU (relu)                            --                        [32, 64, 56, 56]          [32, 64, 56, 56]          --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 64, 56, 56]          [32, 64, 56, 56]          36,928\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 64, 56, 56]          [32, 64, 56, 56]          128\n","│    │    └─ReLU (relu)                            --                        [32, 64, 56, 56]          [32, 64, 56, 56]          --\n","│    └─block (2)                                   --                        [32, 64, 56, 56]          [32, 64, 56, 56]          --\n","│    │    └─Conv2d (conv1)                         [3, 3]                    [32, 64, 56, 56]          [32, 64, 56, 56]          36,928\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 64, 56, 56]          [32, 64, 56, 56]          128\n","│    │    └─ReLU (relu)                            --                        [32, 64, 56, 56]          [32, 64, 56, 56]          --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 64, 56, 56]          [32, 64, 56, 56]          36,928\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 64, 56, 56]          [32, 64, 56, 56]          128\n","│    │    └─ReLU (relu)                            --                        [32, 64, 56, 56]          [32, 64, 56, 56]          --\n","├─Sequential (layer2)                              --                        [32, 64, 56, 56]          [32, 128, 28, 28]         --\n","│    └─block (0)                                   --                        [32, 64, 56, 56]          [32, 128, 28, 28]         --\n","│    │    └─Conv2d (conv1)                         [3, 3]                    [32, 64, 56, 56]          [32, 128, 28, 28]         73,856\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 128, 28, 28]         [32, 128, 28, 28]         256\n","│    │    └─ReLU (relu)                            --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 128, 28, 28]         [32, 128, 28, 28]         147,584\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 128, 28, 28]         [32, 128, 28, 28]         256\n","│    │    └─Sequential (identity_downsample)       --                        [32, 64, 56, 56]          [32, 128, 28, 28]         8,576\n","│    │    └─ReLU (relu)                            --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","│    └─block (1)                                   --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","│    │    └─Conv2d (conv1)                         [3, 3]                    [32, 128, 28, 28]         [32, 128, 28, 28]         147,584\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 128, 28, 28]         [32, 128, 28, 28]         256\n","│    │    └─ReLU (relu)                            --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 128, 28, 28]         [32, 128, 28, 28]         147,584\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 128, 28, 28]         [32, 128, 28, 28]         256\n","│    │    └─ReLU (relu)                            --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","│    └─block (2)                                   --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","│    │    └─Conv2d (conv1)                         [3, 3]                    [32, 128, 28, 28]         [32, 128, 28, 28]         147,584\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 128, 28, 28]         [32, 128, 28, 28]         256\n","│    │    └─ReLU (relu)                            --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 128, 28, 28]         [32, 128, 28, 28]         147,584\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 128, 28, 28]         [32, 128, 28, 28]         256\n","│    │    └─ReLU (relu)                            --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","│    └─block (3)                                   --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","│    │    └─Conv2d (conv1)                         [3, 3]                    [32, 128, 28, 28]         [32, 128, 28, 28]         147,584\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 128, 28, 28]         [32, 128, 28, 28]         256\n","│    │    └─ReLU (relu)                            --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 128, 28, 28]         [32, 128, 28, 28]         147,584\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 128, 28, 28]         [32, 128, 28, 28]         256\n","│    │    └─ReLU (relu)                            --                        [32, 128, 28, 28]         [32, 128, 28, 28]         --\n","├─Sequential (layer3)                              --                        [32, 128, 28, 28]         [32, 256, 14, 14]         --\n","│    └─block (0)                                   --                        [32, 128, 28, 28]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv1)                         [3, 3]                    [32, 128, 28, 28]         [32, 256, 14, 14]         295,168\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 256, 14, 14]         [32, 256, 14, 14]         590,080\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─Sequential (identity_downsample)       --                        [32, 128, 28, 28]         [32, 256, 14, 14]         33,536\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    └─block (1)                                   --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv1)                         [3, 3]                    [32, 256, 14, 14]         [32, 256, 14, 14]         590,080\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 256, 14, 14]         [32, 256, 14, 14]         590,080\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    └─block (2)                                   --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv1)                         [3, 3]                    [32, 256, 14, 14]         [32, 256, 14, 14]         590,080\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 256, 14, 14]         [32, 256, 14, 14]         590,080\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    └─block (3)                                   --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv1)                         [3, 3]                    [32, 256, 14, 14]         [32, 256, 14, 14]         590,080\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 256, 14, 14]         [32, 256, 14, 14]         590,080\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    └─block (4)                                   --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv1)                         [3, 3]                    [32, 256, 14, 14]         [32, 256, 14, 14]         590,080\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 256, 14, 14]         [32, 256, 14, 14]         590,080\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    └─block (5)                                   --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv1)                         [3, 3]                    [32, 256, 14, 14]         [32, 256, 14, 14]         590,080\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 256, 14, 14]         [32, 256, 14, 14]         590,080\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 256, 14, 14]         [32, 256, 14, 14]         512\n","│    │    └─ReLU (relu)                            --                        [32, 256, 14, 14]         [32, 256, 14, 14]         --\n","├─Sequential (layer4)                              --                        [32, 256, 14, 14]         [32, 512, 7, 7]           --\n","│    └─block (0)                                   --                        [32, 256, 14, 14]         [32, 512, 7, 7]           --\n","│    │    └─Conv2d (conv1)                         [3, 3]                    [32, 256, 14, 14]         [32, 512, 7, 7]           1,180,160\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 512, 7, 7]           [32, 512, 7, 7]           1,024\n","│    │    └─ReLU (relu)                            --                        [32, 512, 7, 7]           [32, 512, 7, 7]           --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 512, 7, 7]           [32, 512, 7, 7]           2,359,808\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 512, 7, 7]           [32, 512, 7, 7]           1,024\n","│    │    └─Sequential (identity_downsample)       --                        [32, 256, 14, 14]         [32, 512, 7, 7]           132,608\n","│    │    └─ReLU (relu)                            --                        [32, 512, 7, 7]           [32, 512, 7, 7]           --\n","│    └─block (1)                                   --                        [32, 512, 7, 7]           [32, 512, 7, 7]           --\n","│    │    └─Conv2d (conv1)                         [3, 3]                    [32, 512, 7, 7]           [32, 512, 7, 7]           2,359,808\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 512, 7, 7]           [32, 512, 7, 7]           1,024\n","│    │    └─ReLU (relu)                            --                        [32, 512, 7, 7]           [32, 512, 7, 7]           --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 512, 7, 7]           [32, 512, 7, 7]           2,359,808\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 512, 7, 7]           [32, 512, 7, 7]           1,024\n","│    │    └─ReLU (relu)                            --                        [32, 512, 7, 7]           [32, 512, 7, 7]           --\n","│    └─block (2)                                   --                        [32, 512, 7, 7]           [32, 512, 7, 7]           --\n","│    │    └─Conv2d (conv1)                         [3, 3]                    [32, 512, 7, 7]           [32, 512, 7, 7]           2,359,808\n","│    │    └─BatchNorm2d (bn1)                      --                        [32, 512, 7, 7]           [32, 512, 7, 7]           1,024\n","│    │    └─ReLU (relu)                            --                        [32, 512, 7, 7]           [32, 512, 7, 7]           --\n","│    │    └─Conv2d (conv2)                         [3, 3]                    [32, 512, 7, 7]           [32, 512, 7, 7]           2,359,808\n","│    │    └─BatchNorm2d (bn2)                      --                        [32, 512, 7, 7]           [32, 512, 7, 7]           1,024\n","│    │    └─ReLU (relu)                            --                        [32, 512, 7, 7]           [32, 512, 7, 7]           --\n","├─AdaptiveAvgPool2d (avgpool)                      --                        [32, 512, 7, 7]           [32, 512, 1, 1]           --\n","├─Linear (fc)                                      --                        [32, 512]                 [32, 1000]                513,000\n","======================================================================================================================================================\n","Total params: 21,810,472\n","Trainable params: 21,810,472\n","Non-trainable params: 0\n","Total mult-adds (G): 117.78\n","======================================================================================================================================================\n","Input size (MB): 19.27\n","Forward/backward pass size (MB): 2016.93\n","Params size (MB): 87.24\n","Estimated Total Size (MB): 2123.44\n","======================================================================================================================================================"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":[],"metadata":{"id":"2uRAduE5mzgJ"},"execution_count":null,"outputs":[]}]}