{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN6iN34uMLln6UpNzKeRPL2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ToT2P8yr7Wx8"},"outputs":[],"source":["\"\"\"\n","contains functions to training and testing a Pytorch model\n","\"\"\"\n","import torch\n","\n","from tqdm.auto import tqdm\n","from typing import List, Dict, Tuple\n","\n","def train_step(\n","    model: torch.nn.Module,\n","    dataloader: torch.data.util.DataLoader,\n","    loss_fn: torch.nn.Module,\n","    optimizer: torch.optim.Optimizer\n","    device: torch.device) ->  Tuple[float, float]:\n","\n","    \"\"\"Trains a PyTorch model for a single epoch.\n","    Turns a target PyTorch model to training mode and then\n","    runs through all of the required training steps (forward\n","    pass, loss calculation, optimizer step).\n","    Args:\n","    model: A PyTorch model to be trained.\n","    dataloader: A DataLoader instance for the model to be trained on.\n","    loss_fn: A PyTorch loss function to minimize.\n","    optimizer: A PyTorch optimizer to help minimize the loss function.\n","    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n","    Returns:\n","    A tuple of training loss and training accuracy metrics.\n","    In the form (train_loss, train_accuracy). For example:\n","    (0.1112, 0.8743)\n","    \"\"\"\n","\n","    # put model in train mode\n","    model.train()\n","\n","    # Setup train loss and train accuracy values\n","    train_loss, train_acc = 0, 0 \n","\n","    # Loop through data loader data batches\n","    for batch, (X,y) in enumerate(dataloader):\n","      \n","      # Send data to target device\n","      X, y = X.to(device), y.to(device)\n","      \n","      # 1. Forward pass\n","      y_pred = model(X)\n","\n","      # 2. calculate and accumulate loss\n","      loss = loss_fn(y_pred, y)\n","      train_loss += loss.item()\n","\n","      # 3. Optimizer zero grad\n","      optimizer.zero_grad()\n","\n","      # 4. Loss backward\n","      loss.backword()\n","\n","      # Optimizer step\n","      optimizer.step()\n","\n","      # Calculate and accumulate accuracy metric across all batches\n","      y_pred_class = torch.argmax(troch.softmax(y_pred, dim=1), dim=1)\n","      train_acc += (y_pred_class == y).sum().item() / len(y_pred)\n","\n","    # Adjust metrics to get average loss and accuracy per batch\n","\n","    train_loss = train_loss / len(dataloader)\n","    train_acc = train_acc / len(dataloader)\n","    \n","    return train_loss, train_acc\n","\n","\n","\n","\n"]}]}