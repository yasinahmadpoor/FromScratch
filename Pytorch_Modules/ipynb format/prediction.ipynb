{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM72UGfSx1wRcpoaT8QKN2k"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"iJqYJlrivUyj","executionInfo":{"status":"ok","timestamp":1678090825125,"user_tz":-210,"elapsed":376,"user":{"displayName":"yasin","userId":"00554470259111997069"}}},"outputs":[],"source":["\"\"\"\n","Utility functions to make prediction\n","\"\"\"\n","\n","import torch\n","import torchvision\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","\n","from typing import List, Tuple\n","\n","from PIL import Image\n","\n","#Set device\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# prediction on a target image with a target model \n","\n","def pred_and_plot_image(\n","    model: torch.nn.Module,\n","    class_names: List[str],\n","    image_path: str,\n","    image_size: Tuple[int, int] = (224, 224),\n","    transform: torchvision.transforms = None,\n","    device: torch.device = device\n","):\n","    \"\"\"Predicts on a target image with a target model.\n","    Args:\n","        model (torch.nn.Module): A trained (or untrained) PyTorch model to predict on an image.\n","        class_names (List[str]): A list of target classes to map predictions to.\n","        image_path (str): Filepath to target image to predict on.\n","        image_size (Tuple[int, int], optional): Size to transform target image to. Defaults to (224, 224).\n","        transform (torchvision.transforms, optional): Transform to perform on image. Defaults to None which uses ImageNet normalization.\n","        device (torch.device, optional): Target device to perform prediction on. Defaults to device.\n","    \"\"\"\n","\n","    # Open image\n","    img = Image.open(image_path)\n","\n","    # Create transformation for image (if one doesn't exist)\n","    if transform is not None:\n","        image_transformation = transform\n","    else:\n","        image_transform = transforms.Compose([\n","            transforms.Resize(image_size),\n","            transforms.ToTensor(),\n","            transforms.Normalize(\n","                mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n","            )\n","        ])\n","      \n","    ### Predict on image ###\n","\n","    # Make sure the model is on the target device\n","    model.to(device)\n","\n","    # Turn on model evaluation mode and inference mode\n","    model.eval()\n","    with torch.inference_mode():\n","        # Transform and add an extra dimention to image (model require samples in [batch_size, color_channels, height, width])\n","        transformed_image = image_transform(img).unsqueeze(dim=0)\n","\n","        # Make a prediction on image with a extra dimenstion and send it to the target device\n","        target_image_pred = model(transformed_image.to(device))\n","\n","    # Convert logits -> prediction probabilities -> (using torch.softmax() for multi-class classification)\n","    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n","\n","    # Convert prediction probabilities -> prediction labels\n","    target_image_pred_labels = torch.argmax(target_image_pred_probs, dim=1)\n","\n","\n","    # Plot image with predicted label and probability\n","    plt.figure()\n","    plt.imshow(img)\n","    plt.title(\n","        f\"Pred: {class_names[target_image_pred_labels]} | Prob: {target_image_pred_probs.max():.3f}\"\n","    )\n","\n","    plt.axis(False)\n","\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"jqr4HGfe2_dO"},"execution_count":null,"outputs":[]}]}