{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP3RGxqyrqJprblMfn3idi+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"5a35370c6dc14ee293f77237cdcfece1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b67252c800840fe807a794797e29515","IPY_MODEL_f98a8ce51dc946ddbcb0cd735f9a95a7","IPY_MODEL_4f927e58e79745fa8dcff72607e6e4be"],"layout":"IPY_MODEL_d5a2a41ca62847ff9ecb03ea917dc35e"}},"7b67252c800840fe807a794797e29515":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_787cd84b6e2144729413ecdaf90d843c","placeholder":"​","style":"IPY_MODEL_3b8009e5d4864cb0852a517763387bde","value":"100%"}},"f98a8ce51dc946ddbcb0cd735f9a95a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d415d59878104444a90e5085acd1227a","max":169001437,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc0c241e40da458ebeacb7ecfc3ea633","value":169001437}},"4f927e58e79745fa8dcff72607e6e4be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59df314df2cf46bcb1aa98a3ef89f78d","placeholder":"​","style":"IPY_MODEL_53fccba3ee35413c8a7b487e68196460","value":" 169001437/169001437 [00:11&lt;00:00, 16304245.47it/s]"}},"d5a2a41ca62847ff9ecb03ea917dc35e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"787cd84b6e2144729413ecdaf90d843c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b8009e5d4864cb0852a517763387bde":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d415d59878104444a90e5085acd1227a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc0c241e40da458ebeacb7ecfc3ea633":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"59df314df2cf46bcb1aa98a3ef89f78d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53fccba3ee35413c8a7b487e68196460":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afceb90745bf444b9635d73732aa94cc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_782e00bd599143be90c8b2700647bad1","IPY_MODEL_f9a99966783743cb9ed8c62fee437406","IPY_MODEL_b6c54670d1814e2ab74c0b74efc92b28"],"layout":"IPY_MODEL_c959a82d28d541ab90228393c902a65a"}},"782e00bd599143be90c8b2700647bad1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a1c571029d54a408854c3d288189eff","placeholder":"​","style":"IPY_MODEL_f2ea21be19454f8aa82523ecc48e46d7","value":"100%"}},"f9a99966783743cb9ed8c62fee437406":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_23ba083ce08b428e90e5a754049cd5b3","max":553433881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_da53b9fc32e94d6b9f2e579ec2c953b9","value":553433881}},"b6c54670d1814e2ab74c0b74efc92b28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d1719a40a534774b969ac1bb1c1339b","placeholder":"​","style":"IPY_MODEL_2c463cf1a5b94fa396b9f9b9f62fb75e","value":" 528M/528M [00:04&lt;00:00, 104MB/s]"}},"c959a82d28d541ab90228393c902a65a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a1c571029d54a408854c3d288189eff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2ea21be19454f8aa82523ecc48e46d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23ba083ce08b428e90e5a754049cd5b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da53b9fc32e94d6b9f2e579ec2c953b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8d1719a40a534774b969ac1bb1c1339b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c463cf1a5b94fa396b9f9b9f62fb75e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ckPCjGRJzFc6","executionInfo":{"status":"ok","timestamp":1676294935661,"user_tz":-210,"elapsed":1084,"user":{"displayName":"yasin","userId":"00554470259111997069"}},"outputId":"e876e185-3b3f-4354-a056-e0fa07a5d141"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":4}],"source":["import numpy as np\n","from datetime import datetime \n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import datasets\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","from torchsummary import summary\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"markdown","source":["# VGG16"],"metadata":{"id":"SN1Ne3IWxQ0T"}},{"cell_type":"markdown","source":["VGG is a deep convolutional neural network that was proposed by Karen Simonyan and Andrew Zisserman [1]. VGG is an acronym for their group name, Visual Geometry Group, from the Oxford University. This model secured 2nd place in the ILSVRC-2014 competition where 92.7% classification performance was achieved. The VGG model investigates the depth of layers with a very small convolutional filter size (3 × 3) to deal with large-scale images. The authors released a series of VGG models with different layer lengths, from 11 to 19, which is presented in the following table.\n","\n","* All configurations of VGG have block structures.\n","* Each VGG block consists of a sequence of convolutional layers which are followed by a max-pooling layer. The same kernel size (3 × 3) is applied over all convolutional layers. Besides, the authors used a padding size of 1 to keep the size of the output after each convolutional layer. A max-pooling of size 2 × 2 with strides of 2 is also applied to halve the resolution after each block\n","*Each VGG model has two fully connected hidden layers and one fully connected output layer."],"metadata":{"id":"_Jm2WvOoxJvz"}},{"cell_type":"markdown","source":["<img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/1*NNifzsJ7tD2kAfBXt3AzEg.png' width=700 length=1300 />"],"metadata":{"id":"AJ2_50bcwbbu"}},{"cell_type":"markdown","source":["<img src='https://miro.medium.com/v2/resize:fit:1100/format:webp/1*PEvSaceAL8nNLTco_SYieg.png' width=700 length=1000 />"],"metadata":{"id":"9wH2F10fwvgb"}},{"cell_type":"code","source":["BATCH_SIZE = 32\n","\n","# define transforms\n","# transforms.ToTensor() automatically scales the images to [0,1] range\n","transforms = transforms.Compose([transforms.Resize((227, 227)), transforms.ToTensor()])\n","\n","# download and create datasets\n","train_dataset = datasets.CIFAR100(root='CIFAR100_data', train=True, transform=transforms, download=True)\n","valid_dataset = datasets.CIFAR100(root='CIFAR100_data', train=False, transform=transforms, download=True)\n","\n","# define the data loaders\n","train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","valid_loader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":101,"referenced_widgets":["5a35370c6dc14ee293f77237cdcfece1","7b67252c800840fe807a794797e29515","f98a8ce51dc946ddbcb0cd735f9a95a7","4f927e58e79745fa8dcff72607e6e4be","d5a2a41ca62847ff9ecb03ea917dc35e","787cd84b6e2144729413ecdaf90d843c","3b8009e5d4864cb0852a517763387bde","d415d59878104444a90e5085acd1227a","dc0c241e40da458ebeacb7ecfc3ea633","59df314df2cf46bcb1aa98a3ef89f78d","53fccba3ee35413c8a7b487e68196460"]},"id":"3YPb3Tn8thVi","executionInfo":{"status":"ok","timestamp":1676291306375,"user_tz":-210,"elapsed":15955,"user":{"displayName":"yasin","userId":"00554470259111997069"}},"outputId":"1f99a893-71e5-4918-ce93-b1ae323beb79"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to CIFAR100_data/cifar-100-python.tar.gz\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/169001437 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a35370c6dc14ee293f77237cdcfece1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting CIFAR100_data/cifar-100-python.tar.gz to CIFAR100_data\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["from torch.nn.modules.linear import Linear\n","from torch.nn.modules.container import Sequential\n","class VGG16(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(VGG16, self).__init__()\n","\n","        self.layer1 = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU())\n","        self.layer2 = nn.Sequential(\n","            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2))\n","        self.layer3 = nn.Sequential(\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU())\n","        self.layer4 = nn.Sequential(\n","            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2))\n","        self.layer5 = nn.Sequential(\n","            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU())\n","        self.layer6 = nn.Sequential(\n","            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU())\n","        self.layer7 = nn.Sequential(\n","            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2))\n","        self.layer8 = nn.Sequential(\n","            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU())\n","        self.layer9 = nn.Sequential(\n","            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU())\n","        self.layer10 = nn.Sequential(\n","            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2))\n","        self.layer11 = nn.Sequential(\n","            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU())\n","        self.layer12 = nn.Sequential(\n","            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU())\n","        self.layer13 = nn.Sequential(\n","            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2))\n","        self.fc1 = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(7*7*512, 4096),\n","            nn.ReLU())\n","        self.fc2 = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU())\n","        self.fc3 = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(4096, num_classes))\n","        \n","    def forward(self,x):\n","      out = self.layer1(x)\n","      out = self.layer2(out)\n","      out = self.layer3(out)\n","      out = self.layer4(out)\n","      out = self.layer5(out)\n","      out = self.layer6(out)\n","      out = self.layer7(out)\n","      out = self.layer8(out)\n","      out = self.layer9(out)\n","      out = self.layer10(out)\n","      out = self.layer11(out)\n","      out = self.layer12(out)\n","      out = self.layer13(out)\n","      out = out.reshape(out.size(0),-1)\n","      out = self.fc1(out)\n","      out = self.fc2(out)\n","      logits = self.fc3(out)\n","      probs = F.softmax(logits, dim=1)\n","\n","      return logits, probs\n","\n","\n"],"metadata":{"id":"_YGr5bx-zPcM","executionInfo":{"status":"ok","timestamp":1676294943948,"user_tz":-210,"elapsed":1687,"user":{"displayName":"yasin","userId":"00554470259111997069"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def get_accuracy(model, data_loader, device):\n","    '''\n","    Function for computing the accuracy of the predictions over the entire data_loader\n","    '''\n","\n","    correct_pred = 0\n","    n = 0\n","\n","\n","    with torch.no_grad():\n","        model.eval()\n","        for X,y_true in data_loader:\n","\n","          X = X.to(device)\n","          y_true = y_true.to(device)\n","\n","          _, y_prob = model(X)\n","          _, predicted_labels = torch.max(y_prob,1)\n","\n","          n += y_true.size(0)\n","          correct_pred += (predicted_labels == y_true).sum()\n","\n","    return correct_pred.float() / n\n","\n","def plot_losses(train_losses, valid_losses):\n","    '''\n","    Function for plotting training and validation losses\n","    '''\n","\n","    # temporarily change the style of the plots to seaborn \n","    plt.style.use('seaborn')\n","\n","    train_losses = np.array(train_losses)\n","    valid_losses = np.array(valid_losses)\n","\n","    fig, ax = plt.subplots(figsize = (8, 4.5))\n","    ax.plot(train_losses, color='blue', label= 'Training loss')\n","    ax.plot(valid_losses, color='red', label= 'Validation loss')\n","    ax.set(title='Loss over epochs',\n","           xlabel='Epoch',\n","           ylabel='Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    # change the plot style to default\n","    plt.style.use('default')\n","\n","def train(train_loader, model,criterion, optimizer, device):\n","    '''\n","    Function for the training step of the training loop\n","    '''\n","    \n","    model.train()    \n","    running_loss = 0\n","\n","    for X, y_true in train_loader:\n","\n","        optimizer.zero_grad()           # Sets the gradients of all optimized torch.Tensor s to zero.\n","\n","        X = X.to(device)\n","        y_true = y_true.to(device)\n","\n","        # forward paas\n","        y_hat, _ = model(X)\n","        loss = criterion(y_hat, y_true)\n","        running_loss += loss.item()*X.size(0)        # X.size() ----> Returns the size of the self tensor\n","\n","        # Backward pass\n","        loss.backward()\n","        optimizer.step()\n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","      \n","    return model, optimizer, epoch_loss\n","\n","def validate(valid_loader, model, criterion, device):\n","    '''\n","    Function for the validation step of the training loop\n","    '''\n","   \n","    model.eval()\n","    running_loss = 0\n","    \n","    for X, y_true in valid_loader:\n","    \n","        X = X.to(device)\n","        y_true = y_true.to(device)\n","\n","        # Forward pass and record loss\n","        y_hat, _ = model(X) \n","        loss = criterion(y_hat, y_true) \n","        running_loss += loss.item() * X.size(0)\n","\n","    epoch_loss = running_loss / len(valid_loader.dataset)\n","        \n","    return model, epoch_loss\n","\n","def training_loop(model, criterion, optimizer, lr_scheduler, train_loader, valid_loader,epochs, device, print_every=1):\n","    '''\n","    Function defining the entire training loop\n","    '''\n","\n","    # set objects for storing metrics\n","    best_loss = 1e10\n","    train_losses = []\n","    valid_losses = []\n","\n","\n","    # Train model\n","    for epoch in range(0,epochs):\n","\n","        # training\n","        model, optimizer, train_loss = train(train_loader, model,criterion, optimizer, device)\n","        train_losses.append(train_loss)\n","\n","        # validation\n","        with torch.no_grad():\n","            model, valid_loss = validate(valid_loader, model, criterion, device)\n","            valid_losses.append(valid_loss)\n","\n","            lr_scheduler.step(valid_loss)\n","\n","        if epoch % print_every == (print_every -1):\n","\n","            train_acc = get_accuracy(model, train_loader, device=device)\n","            valid_acc = get_accuracy(model, valid_loader, device=device)\n","\n","            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n","                  f'Epoch: {epoch}\\t'\n","                  f'Train loss: {train_loss:.4f}\\t'\n","                  f'Valid loss: {valid_loss:.4f}\\t'\n","                  f'Train accuracy: {100 * train_acc:.2f}\\t'\n","                  f'Valid accuracy: {100 * valid_acc:.2f}')\n","\n","    plot_losses(train_losses, valid_losses)\n","\n","    return model, optimizer, (train_losses, valid_losses)"],"metadata":{"id":"NDdCFVrN3XKo","executionInfo":{"status":"ok","timestamp":1676294945636,"user_tz":-210,"elapsed":5,"user":{"displayName":"yasin","userId":"00554470259111997069"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Pretrained VGG16"],"metadata":{"id":"my2BlQ9r5viK"}},{"cell_type":"code","source":["import torchvision.models as models\n","model = models.vgg16(pretrained=True)"],"metadata":{"id":"60cWmmnqEPto","executionInfo":{"status":"ok","timestamp":1676294595597,"user_tz":-210,"elapsed":14721,"user":{"displayName":"yasin","userId":"00554470259111997069"}},"colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["afceb90745bf444b9635d73732aa94cc","782e00bd599143be90c8b2700647bad1","f9a99966783743cb9ed8c62fee437406","b6c54670d1814e2ab74c0b74efc92b28","c959a82d28d541ab90228393c902a65a","5a1c571029d54a408854c3d288189eff","f2ea21be19454f8aa82523ecc48e46d7","23ba083ce08b428e90e5a754049cd5b3","da53b9fc32e94d6b9f2e579ec2c953b9","8d1719a40a534774b969ac1bb1c1339b","2c463cf1a5b94fa396b9f9b9f62fb75e"]},"outputId":"c83e4a32-44d4-423f-e3c4-8cb81ddcec6d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/528M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afceb90745bf444b9635d73732aa94cc"}},"metadata":{}}]},{"cell_type":"code","source":["N_EPOCHS = 20\n","LEARNING_RATE = 0.01\n","WEIGHT_DECAY = 0.0005\n","MOMENTUM = 0.9\n","NUM_CLASSES = 100\n","\n","\n","# num_ftrs = model.fc.in_features\n","# Here the size of each output sample is set to 100.\n","# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n","# model.fc = nn.Linear(num_ftrs, 100)\n","model = model.to(device)\n","criterion = nn.CrossEntropyLoss()\n","# Observe that all parameters are being optimized\n","optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n","# Decay LR by a factor of 0.1 every 7 epochs\n","lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1)\n","\n","\n","x = torch.randn(100,3,224,224)\n","x = x.to(device)\n","output = model(x)\n","print(output.shape)\n","summary(model, (3,224,224))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2FxFcrheyykW","executionInfo":{"status":"ok","timestamp":1676295255716,"user_tz":-210,"elapsed":82755,"user":{"displayName":"yasin","userId":"00554470259111997069"}},"outputId":"5f98d84a-ed67-4ce4-c79c-decd70182556"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([100, 1000])\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 224, 224]           1,792\n","              ReLU-2         [-1, 64, 224, 224]               0\n","            Conv2d-3         [-1, 64, 224, 224]          36,928\n","              ReLU-4         [-1, 64, 224, 224]               0\n","         MaxPool2d-5         [-1, 64, 112, 112]               0\n","            Conv2d-6        [-1, 128, 112, 112]          73,856\n","              ReLU-7        [-1, 128, 112, 112]               0\n","            Conv2d-8        [-1, 128, 112, 112]         147,584\n","              ReLU-9        [-1, 128, 112, 112]               0\n","        MaxPool2d-10          [-1, 128, 56, 56]               0\n","           Conv2d-11          [-1, 256, 56, 56]         295,168\n","             ReLU-12          [-1, 256, 56, 56]               0\n","           Conv2d-13          [-1, 256, 56, 56]         590,080\n","             ReLU-14          [-1, 256, 56, 56]               0\n","           Conv2d-15          [-1, 256, 56, 56]         590,080\n","             ReLU-16          [-1, 256, 56, 56]               0\n","        MaxPool2d-17          [-1, 256, 28, 28]               0\n","           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n","             ReLU-19          [-1, 512, 28, 28]               0\n","           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n","             ReLU-21          [-1, 512, 28, 28]               0\n","           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n","             ReLU-23          [-1, 512, 28, 28]               0\n","        MaxPool2d-24          [-1, 512, 14, 14]               0\n","           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n","             ReLU-26          [-1, 512, 14, 14]               0\n","           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n","             ReLU-28          [-1, 512, 14, 14]               0\n","           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n","             ReLU-30          [-1, 512, 14, 14]               0\n","        MaxPool2d-31            [-1, 512, 7, 7]               0\n","AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n","           Linear-33                 [-1, 4096]     102,764,544\n","             ReLU-34                 [-1, 4096]               0\n","          Dropout-35                 [-1, 4096]               0\n","           Linear-36                 [-1, 4096]      16,781,312\n","             ReLU-37                 [-1, 4096]               0\n","          Dropout-38                 [-1, 4096]               0\n","           Linear-39                 [-1, 1000]       4,097,000\n","================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.57\n","Forward/backward pass size (MB): 218.78\n","Params size (MB): 527.79\n","Estimated Total Size (MB): 747.15\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["model, optimizer, _ = training_loop(model, criterion, optimizer, lr_scheduler, train_loader, valid_loader, N_EPOCHS, device)"],"metadata":{"id":"2qnPB9lZ4gpV"},"execution_count":null,"outputs":[]}]}